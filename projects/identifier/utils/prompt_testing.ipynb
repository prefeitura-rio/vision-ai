{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e176cff-5f5f-48a9-b8ed-4a4638860834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import base64\n",
    "import datetime\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import basedosdados as bd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import google.generativeai as genai\n",
    "from langchain import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, chat_models\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "sys.path.insert(0, \"../../\")\n",
    "from utils_sheets import save_data_in_sheets\n",
    "\n",
    "bd.config.billing_project_id = 'rj-escritorio-dev'\n",
    "bd.config.from_file = True\n",
    "bd.__version__\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 1999\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "\n",
    "from vision_ai_api import APIVisionAI\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "# GOOGLE_API_KEY = \"\"\n",
    "PROJECT_ID = \"rj-escritorio-dev\"\n",
    "LOCATION = \"us-central1\"\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7075b49-2121-45b9-915c-495cf89e2ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"secrets.json\") as f:\n",
    "    s = json.load(f)\n",
    "\n",
    "\n",
    "vision_ai_api = APIVisionAI(\n",
    "    username=s.get(\"username\"),\n",
    "    password=s.get(\"password\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66448f1e-84c5-4fc4-9318-79fe9cf4cf42",
   "metadata": {},
   "source": [
    "- storage images: https://console.cloud.google.com/storage/browser/datario-public/flooding_detection?project=datario\n",
    "- imagens figma: https://www.figma.com/file/Qv89NLopXS60Lqf3XfTZiN/Untitled?type=design&node-id=3-44&mode=design&t=3a4g8D4QLiDQ8f3i-0\n",
    "- langchain ref: https://python.langchain.com/docs/integrations/platforms/google\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204531c-8ca9-4c97-a767-d125233a3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_link_from_storage():\n",
    "    dataset_id = \"flooding_detection\"\n",
    "    table_id = \"classified_images\"\n",
    "    st = bd.Storage(dataset_id=dataset_id, table_id=table_id)\n",
    "    blobs = (\n",
    "        st.client[\"storage_staging\"]\n",
    "        .bucket(\"datario-public\")\n",
    "        .list_blobs(prefix=f\"{dataset_id}/{table_id}\")\n",
    "    )\n",
    "\n",
    "    url_list = []\n",
    "    for blob in blobs:\n",
    "        url = str(blob.public_url)\n",
    "        if \".\" in url.split(\"/\")[-1]:\n",
    "            url_list.append(url)\n",
    "    return url_list\n",
    "\n",
    "\n",
    "def get_urls_and_labels():\n",
    "    urls = get_image_link_from_storage()\n",
    "    labels = [\n",
    "        {\"path\": \"images_with_label/flood\", \"label\": True, \"object\": \"alagamento\"},\n",
    "        {\"path\": \"images_with_label/no_flood\", \"label\": False, \"object\": \"alagamento\"},\n",
    "    ]\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        for item in labels:\n",
    "            if item.get(\"path\") in str(url):\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"object\": item.get(\"object\"),\n",
    "                        \"label\": item.get(\"label\"),\n",
    "                        \"image_url\": url,\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def balance_and_sample(df, N):\n",
    "    # Get the minimum count of the two labels\n",
    "    min_count = min(df[\"label\"].value_counts())\n",
    "\n",
    "    # Balance the DataFrame\n",
    "    df_balanced = pd.concat(\n",
    "        [df[df[\"label\"] == True].head(min_count), df[df[\"label\"] == False].head(min_count)]\n",
    "    )\n",
    "    df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "    # Sample N rows\n",
    "    if N > len(df_balanced):\n",
    "        print(\n",
    "            f\"Requested number of samples ({N}) is more than the available balanced dataset size ({len(df_balanced)}).\"\n",
    "        )\n",
    "        return df_balanced\n",
    "    return df_balanced.head(N)\n",
    "\n",
    "\n",
    "def get_image_from_url(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    img.thumbnail((640, 480))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54135f28-635a-41df-b78c-f27dc18f9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, chat_models\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class Object(BaseModel):\n",
    "    object: str = Field(description=\"The object from the objects\")\n",
    "    label_explanation: str = Field(\n",
    "        description=\"Highly detailed visual description of the image given the object context\"\n",
    "    )\n",
    "    label: Union[bool, str, None] = Field(\n",
    "        description=\"Label indicating the condition or characteristic of the object\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ObjectFactory:\n",
    "    @classmethod\n",
    "    def generate_sample(cls) -> Object:\n",
    "        return Object(\n",
    "            object=\"<Object from objects>\",\n",
    "            label_explanation=\"<Visual description of the image given the object context>\",\n",
    "            label=\"<Selected label from objects>\",\n",
    "        )\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    objects: List[Object]\n",
    "\n",
    "\n",
    "class OutputFactory:\n",
    "    @classmethod\n",
    "    def generate_sample(cls) -> Output:\n",
    "        return Output(objects=[ObjectFactory.generate_sample()])\n",
    "\n",
    "\n",
    "class OutputFactory:\n",
    "    @classmethod\n",
    "    def generate_sample(cls) -> Output:\n",
    "        return Output(objects=[ObjectFactory.generate_sample()])\n",
    "\n",
    "\n",
    "def get_parser():\n",
    "\n",
    "    # Create the output parser using the Pydantic model\n",
    "    output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "\n",
    "    # Valid JSON string\n",
    "    output_example_str = str(OutputFactory().generate_sample().dict()).replace(\"'\", '\"')\n",
    "\n",
    "    output_example_str = textwrap.dedent(output_example_str)\n",
    "    output_example = output_parser.parse(output_example_str)\n",
    "    output_example_parsed = json.dumps(output_example.dict(), indent=4)\n",
    "\n",
    "    output_schema = json.loads(output_parser.pydantic_object.schema_json())\n",
    "    output_schema_parsed = json.dumps(output_schema, indent=4)\n",
    "\n",
    "    return output_parser, output_schema_parsed, output_example_parsed\n",
    "\n",
    "\n",
    "def gemini_pro_vision_langchain(\n",
    "    image_url, prompt, max_output_token=300, temperature=0.4, top_k=32, top_p=1\n",
    "):\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-pro-vision\",\n",
    "        google_api_key=GOOGLE_API_KEY,\n",
    "        max_output_token=max_output_token,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    content = [\n",
    "        {\"type\": \"text\", \"text\": prompt},\n",
    "        {\"type\": \"image_url\", \"image_url\": image_url},\n",
    "    ]\n",
    "    message = HumanMessage(content=content)\n",
    "    return llm.invoke([message])\n",
    "\n",
    "\n",
    "def gemini_pro_vision_google(\n",
    "    image_url, prompt, max_output_token=300, temperature=0.4, top_k=32, top_p=1\n",
    "):\n",
    "    image_response = requests.get(image_url)\n",
    "    image = Image.open(io.BytesIO(image_response.content))\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    model = genai.GenerativeModel(\"gemini-pro-vision\")\n",
    "    responses = model.generate_content(\n",
    "        contents=[prompt, image],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": max_output_token,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_k\": top_k,\n",
    "            \"top_p\": top_p,\n",
    "        },\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    responses.resolve()\n",
    "    ai_response = responses.text\n",
    "    return ai_response\n",
    "\n",
    "\n",
    "def gemini_pro_vision_vertex(\n",
    "    image_url, prompt, max_output_token=300, temperature=0.4, top_k=32, top_p=1\n",
    "):\n",
    "    image_response = requests.get(image_url)\n",
    "    image_type = image_url.split(\".\")[-1]\n",
    "    model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    responses = model.generate_content(\n",
    "        contents=[prompt, Part.from_data(image_response.content, f\"image/{image_type}\")],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": max_output_token,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_k\": top_k,\n",
    "            \"top_p\": top_p,\n",
    "        },\n",
    "    )\n",
    "    ai_response = responses.text\n",
    "    return ai_response\n",
    "\n",
    "\n",
    "def predict_and_save(\n",
    "    save_data,\n",
    "    output_parser,\n",
    "    image_url,\n",
    "    prompt,\n",
    "    max_output_token,\n",
    "    temperature,\n",
    "    top_k,\n",
    "    top_p,\n",
    "    experiment_name,\n",
    "    experiment_datetime,\n",
    "    predictions_path,\n",
    "):\n",
    "    response = gemini_pro_vision_vertex(\n",
    "        image_url=image_url,\n",
    "        prompt=prompt,\n",
    "        max_output_token=max_output_token,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response_parsed = output_parser.parse(response)\n",
    "        response_parsed = response_parsed.dict()\n",
    "    except Exception as e:\n",
    "        response_parsed = response\n",
    "\n",
    "    save_data_in_sheets(\n",
    "        save_data=save_data,\n",
    "        data={\n",
    "            \"prompt\": prompt,\n",
    "            \"max_output_token\": max_output_token,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_k\": top_k,\n",
    "            \"top_p\": top_p,\n",
    "            \"experiment_name\": experiment_name,\n",
    "            \"experiment_datetime\": experiment_datetime,\n",
    "            \"true_object\": \"\",\n",
    "            \"response\": response_parsed,\n",
    "            \"image_url\": image_url,\n",
    "            \"image\": f'=IMAGE(\"{image_url}\")',\n",
    "        },\n",
    "        data_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=436224340\",\n",
    "        prompt_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=1779223884\",\n",
    "    )\n",
    "\n",
    "    pd.DataFrame([{\"image_url\": image_url}]).to_csv(\n",
    "        path_or_buf=predictions_path,\n",
    "        index=False,\n",
    "        header=not predictions_path.exists(),\n",
    "        mode=\"a\",\n",
    "    )\n",
    "\n",
    "    return response, response_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe0abf-d0cb-4994-b137-78642a66cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explode_df(dataframe, column_to_explode, prefix=None):\n",
    "    df = dataframe.copy()\n",
    "    exploded_df = df.explode(column_to_explode)\n",
    "    new_df = pd.json_normalize(exploded_df[column_to_explode])\n",
    "\n",
    "    if prefix:\n",
    "        new_df = new_df.add_prefix(f\"{prefix}_\")\n",
    "\n",
    "    df.drop(columns=column_to_explode, inplace=True)\n",
    "    new_df.index = exploded_df.index\n",
    "    result_df = df.join(new_df)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def get_objetcs_labels_df(objects, keep_null=False):\n",
    "    objects_df = objects.rename(columns={\"id\": \"object_id\"})\n",
    "    objects_df = objects_df[[\"name\", \"object_id\", \"labels\"]]\n",
    "    labels = explode_df(objects_df, \"labels\")\n",
    "    if not keep_null:\n",
    "        labels = labels[~labels[\"value\"].isin([\"null\"])]\n",
    "    labels = labels.rename(columns={\"label_id\": \"label\"})\n",
    "    labels = labels.reset_index(drop=True)\n",
    "    return labels\n",
    "\n",
    "\n",
    "with open(\"secrets.json\") as f:\n",
    "    s = json.load(f)\n",
    "\n",
    "vision_api = APIVisionAI(\n",
    "    username=s.get(\"username\"),\n",
    "    password=s.get(\"password\"),\n",
    ")\n",
    "\n",
    "\n",
    "def get_prompt_template():\n",
    "    objects = pd.DataFrame(vision_api._get_all_pages(path=\"/objects\"))\n",
    "    labels = get_objetcs_labels_df(objects, keep_null=True)\n",
    "\n",
    "    data = vision_api._get_all_pages(path=\"/prompts\")\n",
    "    prompt_parameters = data[0]\n",
    "    prompt_text = prompt_parameters.get(\"prompt_text\")\n",
    "    prompt_objects = prompt_parameters.get(\"objects\")\n",
    "\n",
    "    selected_labels_cols = [\"name\", \"criteria\", \"identification_guide\", \"value\"]\n",
    "    labels = labels[selected_labels_cols]\n",
    "    labels = labels[labels[\"name\"].isin(prompt_objects)]\n",
    "    labels = labels.rename(columns={\"name\": \"object\", \"value\": \"label\"})\n",
    "    objects_table_md = labels.to_markdown(index=False)\n",
    "    # prompt_text =  prompt_text.replace(\"{objects_table_md}\", objects_table_md)\n",
    "\n",
    "    prompt_parameters[\"prompt_text\"] = prompt_text\n",
    "    prompt_parameters[\"objects_table_md\"] = objects_table_md\n",
    "\n",
    "    return prompt_parameters\n",
    "\n",
    "\n",
    "def get_urls_from_path(url_path):\n",
    "    urls = get_image_link_from_storage()\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        if url_path in str(url):\n",
    "            data.append(\n",
    "                {\n",
    "                    \"image_url\": url,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def get_objects_table_from_sheets(\n",
    "    url: str = \"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=1672006844\",\n",
    "):\n",
    "    request_url = url.replace(\"edit#gid=\", \"export?format=csv&gid=\")\n",
    "    response = requests.get(request_url)\n",
    "    dataframe = pd.read_csv(io.StringIO(response.content.decode(\"utf-8\")), dtype=str)\n",
    "    dataframe[\"label\"] = dataframe[\"label\"].fillna(\"null\")\n",
    "    dataframe = dataframe[dataframe[\"use\"] == \"1\"]\n",
    "    dataframe = dataframe.drop(columns=[\"use\"])\n",
    "\n",
    "    objects_table_md = dataframe.to_markdown(index=False)\n",
    "\n",
    "    objects_labels = (\n",
    "        dataframe[[\"object\", \"label\"]]\n",
    "        .groupby(by=[\"object\"], sort=False)[\"label\"]\n",
    "        .apply(lambda x: \", \".join(x))\n",
    "        .reset_index()\n",
    "    )\n",
    "    objects_labels[\"label\"] = objects_labels[\"label\"].str.replace(\"true, false\", \"bool\")\n",
    "\n",
    "    objects_labels_md = objects_labels.to_markdown(index=False)\n",
    "    objects_labels_md = objects_labels_md\n",
    "    return objects_table_md, objects_labels_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4e698-9a4a-4c53-93a3-f3d8ce29a3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1400caf-50f1-45c5-965d-1ad59e209b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(prompt_parameters, prompt_template=None, objects_table_md=None):\n",
    "\n",
    "    if not prompt_template:\n",
    "        prompt_template = prompt_parameters.get(\"prompt_text\")\n",
    "\n",
    "    _, output_schema, output_example = get_parser()\n",
    "\n",
    "    if not objects_table_md:\n",
    "        objects_table_md = prompt_parameters.get(\"objects_table_md\")\n",
    "\n",
    "    filled_prompt = (\n",
    "        prompt_template.replace(\"                        \", \"\")\n",
    "        .replace(\"{objects_table_md}\", objects_table_md)\n",
    "        .replace(\"{output_schema}\", output_schema)\n",
    "        .replace(\"{output_example}\", output_example)\n",
    "    )\n",
    "\n",
    "    return filled_prompt, prompt_template\n",
    "\n",
    "\n",
    "backup = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt_text_local = \"\"\"\n",
    "\n",
    "## Role: Urban Road Image Analyst\n",
    "\n",
    "#### Expertise and Responsibilities:\n",
    "As an Expert Urban Road Image Analyst, you specialize in interpreting CCTV images to assess various conditions on urban roads. Your expertise includes the detection of image data loss or corruption, as well as analyzing.\n",
    "\n",
    "\n",
    "#### Key Expertise Areas:\n",
    "- **Image Data Integrity Analysis:** Expertise in identifying signs of image data loss or corruption, such as uniform grey or green color distortions.\n",
    "- **Urban Road Condition Assessment:** Proficient in evaluating road conditions and potential hazards unrelated to specific environmental factors.\n",
    "- **Visual Data Interpretation:** Skilled in analyzing visual data from CCTV images, recognizing patterns and indicators that reflect road conditions and safety issues.\n",
    "\n",
    "#### Skills:\n",
    "- **Analytical Prowess:** Exceptional ability to analyze complex visual data, detecting subtle indicators of road-related challenges.\n",
    "- **Detail-Oriented Observation:** Keen observational skills for identifying minute details in CCTV footage that signify changes in road conditions.\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "### Input\n",
    "\n",
    "- **Data Provided**: A CCTV image.\n",
    "\n",
    "### Objects Table \n",
    "\n",
    "- **Guidance**: Use the table below for object classification, adhering to the specified criteria and identification guides.\n",
    "\n",
    "{objects_table_md}\n",
    "\n",
    "### Scenarios examples:\n",
    "\n",
    "- Example 1: Dry Road with Clear Traffic\n",
    "```json\n",
    "{\n",
    "    \"objects\": [\n",
    "        {\n",
    "            \"object\": \"image_corrupted\",\n",
    "            \"label_explanation\": \"Image is clear, no distortion or data loss.\",\n",
    "            \"label\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"image_description\",\n",
    "            \"label_explanation\": \"Urban road in daylight with vehicles, clear weather.\",\n",
    "            \"label\": \"null\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"rain\",\n",
    "            \"label_explanation\": \"Road surface is dry, no signs of water.\",\n",
    "            \"label\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"water_level\",\n",
    "            \"label_explanation\": \"No water present, road surface completely dry.\",\n",
    "            \"label\": \"low\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"traffic\",\n",
    "            \"label_explanation\": \"Traffic is flowing smoothly, no hindrance observed.\",\n",
    "            \"label\": \"easy\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"road_blockade\",\n",
    "            \"label_explanation\": \"Road is completely free of obstructions.\",\n",
    "            \"label\": \"free\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "- Example 2: Partially Flooded Road with Moderate Obstructions\n",
    "```json\n",
    "{\n",
    "    \"objects\": [\n",
    "        {\n",
    "            \"object\": \"image_corrupted\",\n",
    "            \"label_explanation\": \"Slight blurriness in the image, but generally clear.\",\n",
    "            \"label\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"image_description\",\n",
    "            \"label_explanation\": \"Moderate traffic on an urban road with visible puddles.\",\n",
    "            \"label\": \"null\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"rain\",\n",
    "            \"label_explanation\": \"Puddles observed on parts of the road.\",\n",
    "            \"label\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"water_level\",\n",
    "            \"label_explanation\": \"Water covers some parts of the road, forming puddles.\",\n",
    "            \"label\": \"medium\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"traffic\",\n",
    "            \"label_explanation\": \"Traffic moving slower due to water on road.\",\n",
    "            \"label\": \"moderate\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"road_blockade\",\n",
    "            \"label_explanation\": \"Partial obstructions due to water, but traffic can pass.\",\n",
    "            \"label\": \"partially\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "- Example 3: Fully Flooded and Blocked Road\n",
    "```json\n",
    "{\n",
    "    \"objects\": [\n",
    "        {\n",
    "            \"object\": \"image_corrupted\",\n",
    "            \"label_explanation\": \"High quality, clear image with no issues.\",\n",
    "            \"label\": \"false\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"image_description\",\n",
    "            \"label_explanation\": \"Road completely submerged in water, no traffic visible.\",\n",
    "            \"label\": \"null\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"rain\",\n",
    "            \"label_explanation\": \"Road is fully covered in water.\",\n",
    "            \"label\": \"true\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"water_level\",\n",
    "            \"label_explanation\": \"Water level high, road completely submerged.\",\n",
    "            \"label\": \"high\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"traffic\",\n",
    "            \"label_explanation\": \"Traffic is impossible due to severe flooding.\",\n",
    "            \"label\": \"impossible\"\n",
    "        },\n",
    "        {\n",
    "            \"object\": \"road_blockade\",\n",
    "            \"label_explanation\": \"Road is entirely blocked by flooding, impassable.\",\n",
    "            \"label\": \"totally\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "### Output\n",
    "\n",
    "**Output Order**\n",
    "\n",
    "- **Sequence**: Follow this order in your analysis: \n",
    "    1. image_corrupted: true or false\n",
    "    2. image_description: allways null\n",
    "    3. rain: true or false\n",
    "    4. water_level: low, medium or high\n",
    "    5. traffic: easy, moderate, difficult or impossible\n",
    "    6. road_blockade: free, partially or totally\n",
    "\n",
    "- **Importance**: Adhering to this sequence ensures logical and coherent analysis, with each step informing the subsequent ones.\n",
    "\n",
    "\n",
    "\n",
    "**Example Format** \n",
    "\n",
    "- Present findings in a structured JSON format, following the provided example.\n",
    "        \n",
    "```json\n",
    "{output_example}\n",
    "```\n",
    "\n",
    "- **Requirement**: Each label_explanation should be a 500-word interpretation of the image, demonstrating a deep understanding of the visible elements.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# # PUT PROMPT\n",
    "# prompt_parameters = vision_ai_api._get('/prompts').get('items')[0]\n",
    "# prompt_id = prompt_parameters.get('id')\n",
    "# request_body = {\n",
    "#   \"name\": prompt_parameters.get(\"name\"),\n",
    "#   \"model\": prompt_parameters.get(\"model\"),\n",
    "#   \"prompt_text\": prompt_text_local,\n",
    "#   \"max_output_token\": prompt_parameters.get(\"max_output_token\"),\n",
    "#   \"temperature\": 0.1,\n",
    "#   \"top_k\": prompt_parameters.get(\"top_k\"),\n",
    "#   \"top_p\": prompt_parameters.get(\"top_p\")\n",
    "# }\n",
    "\n",
    "\n",
    "# r = vision_ai_api._put(\n",
    "#     path=f'/prompts/{prompt_id}',\n",
    "#     json_data=request_body\n",
    "# )\n",
    "# print(json.dumps(r.json(),  indent=2))\n",
    "\n",
    "\n",
    "# Markdown(prompt_text_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14af78a-f5b7-45ac-928d-6d8ca919332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = get_urls_from_path(url_path=\"images_predicted_as_flood\")\n",
    "objects_table_md, objects_labels_md = get_objects_table_from_sheets()\n",
    "df = get_urls_from_path(url_path=\"/\")\n",
    "prompt_parameters = get_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3693d-cf6e-4988-98c3-4503db2aba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"test-object-label-table\"\n",
    "experiment_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "max_output_token = prompt_parameters.get(\"max_output_token\")\n",
    "temperature = 0.6\n",
    "top_k = prompt_parameters.get(\"top_k\")\n",
    "top_p = prompt_parameters.get(\"top_p\")\n",
    "retry = 5\n",
    "\n",
    "prompt, prompt_template = get_prompt(\n",
    "    prompt_parameters, prompt_template=prompt_text_local, objects_table_md=objects_table_md\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4d670-030f-46c3-ae73-fc53f02032e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(prompt))\n",
    "Markdown(prompt)\n",
    "\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b47a46-398f-4114-85d4-684752ccac6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_path = Path(f\"./data/predictions/{experiment_name}__{experiment_datetime}.csv\")\n",
    "\n",
    "if predictions_path.exists():\n",
    "    predictions = pd.read_csv(predictions_path)\n",
    "    predictions_list = predictions[\"image_url\"].tolist()\n",
    "else:\n",
    "    predictions_list = []\n",
    "\n",
    "output_parser, output_schema, output_example = get_parser()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image_url = row[\"image_url\"]\n",
    "    retry_count = 0\n",
    "    while retry_count <= retry:\n",
    "        try:\n",
    "            if image_url not in predictions_list:\n",
    "                _response = None\n",
    "                _response, response_parsed = predict_and_save(\n",
    "                    save_data=True,\n",
    "                    output_parser=output_parser,\n",
    "                    image_url=image_url,\n",
    "                    prompt=prompt,\n",
    "                    max_output_token=max_output_token,\n",
    "                    temperature=temperature,\n",
    "                    top_k=top_k,\n",
    "                    top_p=top_p,\n",
    "                    experiment_name=experiment_name,\n",
    "                    experiment_datetime=experiment_datetime,\n",
    "                    predictions_path=predictions_path,\n",
    "                )\n",
    "\n",
    "                print(f\"{index} - {len(df)}\")\n",
    "                # print(json.dumps(response_parsed, indent=4))\n",
    "                # display(get_image_from_url(image_url))\n",
    "            else:\n",
    "                print(f\"{index} - {len(df)}: already predicted\")\n",
    "\n",
    "            retry_count = retry + 1\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"{index} - {len(df)}: Error.. Retrying:{retry_count}\\n {e}\\n\\n\\n\\nAI Response:\")\n",
    "            print(_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad9663-727a-4620-8525-f2803bde51e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4512007-5a73-426e-a2a8-59e2997881b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3defb987-2795-43f8-ac61-93e34206fc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149fe35-3aed-4d2c-84d5-4fe74b35ebbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb829be-4a45-4d8d-bc88-42b486c7b9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2617a8eb-d39f-43e2-8aab-4b662f39e4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f0ff8-d34f-486e-b839-00df334ef541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d529d0-afa9-4d11-9a84-063e6764492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Objects Tables to Markdown\n",
    "\n",
    "# prompt_parameters = vision_ai_api._get('/prompts').get('items')[0]\n",
    "# df = get_objects_table_from_sheets()\n",
    "\n",
    "# markdown_str = \"\"\n",
    "# for object_name in df['object'].unique().tolist():\n",
    "#     labels_df = df[df['object']==object_name]\n",
    "#     i = 0\n",
    "#     for _, row   in labels_df.iterrows():\n",
    "#         if i==0:\n",
    "#             markdown_str += f\"\\nObject: {object_name}\\n\"\n",
    "\n",
    "#         markdown_str+=f\"\"\"\n",
    "#             - Label: {row['labels']}:\n",
    "#                 - Criteria: {row['criteria']}\n",
    "#                 - Identification guide: {row['identification_guide']}\n",
    "#         \"\"\".replace(\"            \",\"\")\n",
    "\n",
    "\n",
    "#         i+=1\n",
    "\n",
    "# markdown_str = markdown_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1ef0b8-bbeb-4a8c-8573-9fe97ae08527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1399960-9aec-4073-a795-48c1bfdc3667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36947ea5-f032-4ce9-9743-bdf0a9fde682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05adb4b9-a7e7-4a2b-927d-0d38a5466434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1145a2-8260-46ec-bb03-b9dcd859ebe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04e2a6-ecdb-4b86-b125-1c35aae3b916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac9f08-33c6-4a33-8d2c-a7ffadbf2b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-pro-vision\")\n",
    "model.generate_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b4c78-5a41-4a3d-8154-2b49f3ad24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efc556-4562-4bfa-8ef8-7c894a234990",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79bb0e-a989-48ec-9e20-7840794439eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_id = \"001477\"\n",
    "N = 100\n",
    "for i, image_url in enumerate(\n",
    "    N * [f\"https://storage.googleapis.com/datario-public/vision-ai/staging/{camera_id}.png\"]\n",
    "):\n",
    "    retry_count = 0\n",
    "    while retry_count <= retry:\n",
    "        try:\n",
    "            response, response_parsed = predict_and_save(\n",
    "                save_data=True,\n",
    "                output_parser=output_parser,\n",
    "                image_url=image_url,\n",
    "                prompt=prompt,\n",
    "                max_output_token=max_output_token,\n",
    "                temperature=temperature,\n",
    "                top_k=top_k,\n",
    "                top_p=top_p,\n",
    "            )\n",
    "\n",
    "            print(f\"{i}\")\n",
    "            # print(json.dumps(response_parsed, indent=4))\n",
    "            # display(get_image_from_url(image_url))\n",
    "            retry_count = retry + 1\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"{i}: Error.. Retrying:{retry_count}\\n {e}\\n\\n\\n\\nAI Response:\")\n",
    "            print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084e9e8-3a53-49fc-a34c-fab80aa570f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a81b6-0840-4c0c-b3b7-b287a408f738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de45f6-5f96-4bd0-889f-1c77de15e247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2de343-2021-4b9d-bdec-5fad2713b942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6d823-1be5-41b4-a30a-e8775a8fff20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d617e71e-a3d1-45c3-bf59-3dbad561fad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d42160-cc20-4afe-b88e-cfe5675e3b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6936a0-ded2-4ae8-8817-64fcde85bffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ae79b-fb54-404a-a7d6-4c8889282e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7d4d6-e96e-41fe-9385-346a74d9398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35215f-8f6d-4b8a-98f3-5c7ef1c7ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser.parse(response_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e012c-8c4e-42d6-a915-9c04de0ae0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f459c94-045e-477d-9e2d-4daae12c3a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557a65b-d976-43d2-ae29-fadba8336f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e416e7-f770-4758-80c1-616e788e4d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b1675-9ed5-41a3-96de-ea07b5a17cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ad56f-48c0-493c-8010-2d477f75e015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a93eef-6414-40ca-a260-05b363514053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4d874-13f5-4fc5-9535-2ceb4f35c6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363487d0-abf1-4810-bd4e-af6ecdc9bd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef2392-2b12-4b5f-adbb-d7ac8808a183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0981861-bf78-4313-9707-78fbeed07676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f41b9-72f9-4ff4-a92b-90467f0d6985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25eb26-86d0-4fbd-baed-32eea8413c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8eb834-0fda-43a1-a48d-38ccfc620cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249ce22-8953-425f-b048-3799f4132320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f633618-b120-46a9-bebf-571115518247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a583ac5-28e6-4172-8254-87fcbba4dcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af26c7-c932-44fc-8ff6-06bfd9449586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63777b1b-9c46-4d4e-81e9-02f8434ce218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320dc68c-282d-42e0-8560-d7efd730678d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8311f0e-d371-431d-87bf-a12cb150c6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f66e1-9636-4e51-9818-a74ac476259a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5aaa57-c42b-4a9d-a641-2fac9f04a490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e727eb-a617-4360-863e-aeb2b16af3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8072c17-f764-4091-98bd-e9a7e04ecb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948454c4-478a-42b2-8888-c0ee53604edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c131bba-ce3d-4166-b29b-da2209dfa26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65073a69-14c4-429e-8f54-77216854c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "true_values = df_final[\"flood\"].tolist()\n",
    "predicted_values = df_final[\"ai_label\"].tolist()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_values, predicted_values)\n",
    "precision = precision_score(true_values, predicted_values, pos_label=True)\n",
    "recall = recall_score(true_values, predicted_values, pos_label=True)\n",
    "f1 = f1_score(true_values, predicted_values, pos_label=True)\n",
    "conf_matrix = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"False\", \"True\"],\n",
    "    yticklabels=[\"False\", \"True\"],\n",
    ")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# resize_factor = 3\n",
    "# imgs = 10\n",
    "# time = 1:00\n",
    "# Accuracy: 0.7\n",
    "# Precision: 0.6666666666666666\n",
    "# Recall: 0.5\n",
    "# F1 Score: 0.5714285714285715\n",
    "\n",
    "# resize_factor = 1\n",
    "# imgs = 10\n",
    "# time = 1:15\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75\n",
    "\n",
    "\n",
    "# resize_factor = 5\n",
    "# imgs = 10\n",
    "# time = 1:20\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc24eb2-79a9-4008-a62d-68352822cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"miss\"] = np.where(df_final[\"flood\"] == df_final[\"ai_label\"], False, True)\n",
    "mask = df_final[\"miss\"] == True\n",
    "miss = df_final[mask]\n",
    "miss_imgs = miss[\"base64\"].tolist()\n",
    "miss_ai_labels = miss[\"ai_label\"].tolist()\n",
    "\n",
    "\n",
    "for base64_image, ai_label in zip(miss_imgs, miss_ai_labels):\n",
    "    print(f\"AI classyfy as: {ai_label}\")\n",
    "    display_img(base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77779a-d488-4f08-8aea-52394f9741e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ef146-77b9-4969-bce0-c27dc606059b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b32695b-c8a0-46d8-a5e4-2121f88ac158",
   "metadata": {},
   "source": [
    "You are a highly skilled prompt engineering focus in create prompts for CCTV image recognition. Your task is to optimize and refine a provided example prompt.\n",
    "\n",
    "you output is a diff between the provided prompt and the new optmized prompt\n",
    "\n",
    "shall we start?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b74ec-93a9-4328-862f-54c3f1162e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Escritorio de Dados - Default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
