{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e176cff-5f5f-48a9-b8ed-4a4638860834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "import textwrap\n",
    "\n",
    "from utils.utils import normalize_cols\n",
    "from utils_sheets import save_data_in_sheets\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import basedosdados as bd\n",
    "\n",
    "\n",
    "bd.config.billing_project_id = 'rj-escritorio-dev'\n",
    "bd.config.from_file = True\n",
    "bd.__version__\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 1999\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66448f1e-84c5-4fc4-9318-79fe9cf4cf42",
   "metadata": {},
   "source": [
    "- storage images: https://console.cloud.google.com/storage/browser/datario-public/flooding_detection?project=datario\n",
    "- imagens figma: https://www.figma.com/file/Qv89NLopXS60Lqf3XfTZiN/Untitled?type=design&node-id=3-44&mode=design&t=3a4g8D4QLiDQ8f3i-0\n",
    "- langchain ref: https://python.langchain.com/docs/integrations/platforms/google\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204531c-8ca9-4c97-a767-d125233a3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_link_from_storage():\n",
    "    dataset_id = \"flooding_detection\"\n",
    "    table_id = \"classified_images\"\n",
    "    st = bd.Storage(dataset_id=dataset_id, table_id=table_id)\n",
    "    blobs = (\n",
    "        st.client[\"storage_staging\"]\n",
    "        .bucket(\"datario-public\")\n",
    "        .list_blobs(prefix=f\"{dataset_id}/{table_id}\")\n",
    "    )\n",
    "\n",
    "    url_list = []\n",
    "    for blob in blobs:\n",
    "        url = str(blob.public_url)\n",
    "        if \".\" in url.split(\"/\")[-1]:\n",
    "            url_list.append(url)\n",
    "    return url_list\n",
    "\n",
    "\n",
    "def get_urls_and_labels():\n",
    "    urls = get_image_link_from_storage()\n",
    "    labels = [\n",
    "        {\"path\": \"images_with_label/flood\", \"label\": True, \"object\": \"alagamento\"},\n",
    "        {\"path\": \"images_with_label/no_flood\", \"label\": False, \"object\": \"alagamento\"},\n",
    "    ]\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        for item in labels:\n",
    "            if item.get(\"path\") in str(url):\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"object\": item.get(\"object\"),\n",
    "                        \"label\": item.get(\"label\"),\n",
    "                        \"image_url\": url,\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def balance_and_sample(df, N):\n",
    "    # Get the minimum count of the two labels\n",
    "    min_count = min(df[\"label\"].value_counts())\n",
    "\n",
    "    # Balance the DataFrame\n",
    "    df_balanced = pd.concat(\n",
    "        [df[df[\"label\"] == True].head(min_count), df[df[\"label\"] == False].head(min_count)]\n",
    "    )\n",
    "    df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "    # Sample N rows\n",
    "    if N > len(df_balanced):\n",
    "        print(\n",
    "            f\"Requested number of samples ({N}) is more than the available balanced dataset size ({len(df_balanced)}).\"\n",
    "        )\n",
    "        return df_balanced\n",
    "    return df_balanced.head(N)\n",
    "\n",
    "\n",
    "# OpenAI API Key\n",
    "\n",
    "\n",
    "def get_image_from_url(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    img.thumbnail((640, 480))\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_ai_label(response):\n",
    "    if response.get(\"error\"):\n",
    "        return \"Error\"\n",
    "    else:\n",
    "        # r = response['choices'][0]['message']['content']\n",
    "        json_string = r.replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "        json_object = json.loads(json_string)\n",
    "        return json_object[\"label\"]\n",
    "\n",
    "\n",
    "def get_ai_label_gemini(response):\n",
    "    if type(response) == tuple:\n",
    "        response = response[0]\n",
    "    json_string = str(response).replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "    json_object = json.loads(json_string)\n",
    "    return json_object[\"label\"]\n",
    "\n",
    "\n",
    "def gemini_pro_vision_classify_image(image):\n",
    "    prompt = \"\"\"\n",
    "            \"You are an expert flooding detector. You are\n",
    "            given a image. You must detect if there is flooding in the image. The output MUST\n",
    "            be a JSON object with a boolean value for the key \"\"label\"\". If you don't\n",
    "            know what to anwser, you can set the key \"\"label\"\" as false. Example:\n",
    "            {\n",
    "                \"\"label\"\": true\n",
    "            }\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-pro-vision\")\n",
    "        responses = model.generate_content(\n",
    "            contents=[prompt, image],\n",
    "            generation_config={\n",
    "                \"max_output_tokens\": 2048,\n",
    "                \"temperature\": 0.4,\n",
    "                \"top_p\": 1,\n",
    "                \"top_k\": 32,\n",
    "            },\n",
    "            stream=True,\n",
    "        )\n",
    "        responses.resolve()\n",
    "        return (responses.text, True, None)\n",
    "    except Exception as e:\n",
    "        return (' {\\n  \"label\": false\\n}', False, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54135f28-635a-41df-b78c-f27dc18f9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, chat_models\n",
    "\n",
    "\n",
    "def get_content():\n",
    "    image_classificacao = \"https://storage.googleapis.com/datario-public/flooding_detection/prompt_images/exemplos_classificacao.png\"\n",
    "    image_exemplo = \"https://storage.googleapis.com/datario-public/flooding_detection/prompt_images/bolsao_dagua.png\"\n",
    "    content = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"\"\"\n",
    "                You are an expert flooding detector. \n",
    "                Given an image, you must detect the following categories otherwise return null:\n",
    "                 - lamina_dagua: Area with water up to 15 cm, possible to identify a pedestrian with water up to their ankles.\n",
    "                 - bolsao_dagua: Accumulation of water between 15 and 30 cm, small vehicle with water reaching a quarter of the height of the wheels.\n",
    "                 - alagamento: Water between 30 and 50 cm, vehicles partially submerged, with water up to half the wheels.\n",
    "                 - null: None of the above descriptions\n",
    "                \n",
    "                Using this examples from the image:\n",
    "                \n",
    "            \"\"\",\n",
    "        },  # You can optionally provide text parts\n",
    "        {\"type\": \"image_url\", \"image_url\": image_classificacao},\n",
    "        # example\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"\"\"\n",
    "                INPUT\n",
    "                A CCTV image.\n",
    "\n",
    "                OUTPUT\n",
    "                The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
    "\n",
    "                ```json\n",
    "                {\n",
    "                    \"object\": string  // answer to the user's question\n",
    "                    \"explanation\": string  // Explanation for the object and object classification\n",
    "                }\n",
    "                ```\n",
    "                \n",
    "                Example:\n",
    "                \n",
    "                OUTPUT:\n",
    "                ```json\n",
    "                {\n",
    "                    \"object\": \"bolsao_dagua\",\n",
    "                    \"explanation\": \"Because ...\"\n",
    "                }\n",
    "                ```\n",
    "                INPUT:\n",
    "                \n",
    "            \"\"\",\n",
    "        },\n",
    "        {\"type\": \"image_url\", \"image_url\": image_exemplo},\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": \"Now classify the image bellow:\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for d in content:\n",
    "        for key, value in d.items():\n",
    "            d[key] = textwrap.dedent(value)\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def gemini_pro_vision_langchain(\n",
    "    image_url, content, max_output_token=300, temperature=0.4, top_k=32, top_p=1\n",
    "):\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-pro-vision\",\n",
    "        google_api_key=GOOGLE_API_KEY,\n",
    "        max_output_token=max_output_token,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "\n",
    "    message = HumanMessage(content=content + [{\"type\": \"image_url\", \"image_url\": image_url}])\n",
    "    return llm.invoke([message])\n",
    "\n",
    "\n",
    "def get_parser():\n",
    "    from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "    response_schemas = [\n",
    "        ResponseSchema(name=\"object\", description=\"answer to the user's question\"),\n",
    "        ResponseSchema(\n",
    "            name=\"explanation\", description=\"Explanation for the object and object classification\"\n",
    "        ),\n",
    "    ]\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "    return output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3693d-cf6e-4988-98c3-4503db2aba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_from_path(url_path):\n",
    "    urls = get_image_link_from_storage()\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        if url_path in str(url):\n",
    "            data.append(\n",
    "                {\n",
    "                    \"image_url\": url,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df = get_urls_from_path(url_path=\"images_predicted_as_flood\")\n",
    "\n",
    "\n",
    "experiment_name = \"test\"\n",
    "experiment_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "content = get_content()\n",
    "max_output_token = 300\n",
    "temperature = 0.4\n",
    "top_k = 32\n",
    "top_p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b47a46-398f-4114-85d4-684752ccac6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "predictions_path = Path(f\"./data/predictions/{experiment_name}__{experiment_datetime}.csv\")\n",
    "\n",
    "if predictions_path.exists():\n",
    "    predictions = pd.read_csv(predictions_path)\n",
    "    predictions_list = predictions[\"image_url\"].tolist()\n",
    "else:\n",
    "    predictions_list = []\n",
    "\n",
    "output_parser = get_parser()\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image_url = row[\"image_url\"]\n",
    "    if image_url not in predictions_list:\n",
    "        response = gemini_pro_vision_langchain(\n",
    "            image_url=image_url,\n",
    "            content=content,\n",
    "            max_output_token=max_output_token,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "        )\n",
    "        response_parsed = output_parser.parse(response.content)\n",
    "        response_parsed[\"image_url\"] = image_url\n",
    "\n",
    "        print(f\"{index} - {len(df)}\")\n",
    "        print(json.dumps(response_parsed, indent=4))\n",
    "        display(get_image_from_url(image_url))\n",
    "\n",
    "        save_data_in_sheets(\n",
    "            save_data=True,\n",
    "            data={\n",
    "                \"content\": get_content(),\n",
    "                \"max_output_token\": max_output_token,\n",
    "                \"temperature\": temperature,\n",
    "                \"top_k\": top_k,\n",
    "                \"top_p\": top_p,\n",
    "                \"experiment_name\": experiment_name,\n",
    "                \"experiment_datetime\": experiment_datetime,\n",
    "                \"true_object\": \"\",\n",
    "                \"object\": response_parsed.get(\"object\", \"\"),\n",
    "                \"explanation\": response_parsed.get(\"explanation\", \"\"),\n",
    "                \"image_url\": image_url,\n",
    "                \"image\": f'=IMAGE(\"{image_url}\")',\n",
    "            },\n",
    "            data_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=436224340\",\n",
    "            content_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=1779223884\",\n",
    "        )\n",
    "\n",
    "        pd.DataFrame([response_parsed]).to_csv(\n",
    "            path_or_buf=predictions_path,\n",
    "            index=False,\n",
    "            header=not predictions_path.exists(),\n",
    "            mode=\"a\",\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{index} - {len(df)}: already predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e727eb-a617-4360-863e-aeb2b16af3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8072c17-f764-4091-98bd-e9a7e04ecb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948454c4-478a-42b2-8888-c0ee53604edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c131bba-ce3d-4166-b29b-da2209dfa26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65073a69-14c4-429e-8f54-77216854c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "true_values = df_final[\"flood\"].tolist()\n",
    "predicted_values = df_final[\"ai_label\"].tolist()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_values, predicted_values)\n",
    "precision = precision_score(true_values, predicted_values, pos_label=True)\n",
    "recall = recall_score(true_values, predicted_values, pos_label=True)\n",
    "f1 = f1_score(true_values, predicted_values, pos_label=True)\n",
    "conf_matrix = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"False\", \"True\"],\n",
    "    yticklabels=[\"False\", \"True\"],\n",
    ")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# resize_factor = 3\n",
    "# imgs = 10\n",
    "# time = 1:00\n",
    "# Accuracy: 0.7\n",
    "# Precision: 0.6666666666666666\n",
    "# Recall: 0.5\n",
    "# F1 Score: 0.5714285714285715\n",
    "\n",
    "# resize_factor = 1\n",
    "# imgs = 10\n",
    "# time = 1:15\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75\n",
    "\n",
    "\n",
    "# resize_factor = 5\n",
    "# imgs = 10\n",
    "# time = 1:20\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc24eb2-79a9-4008-a62d-68352822cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"miss\"] = np.where(df_final[\"flood\"] == df_final[\"ai_label\"], False, True)\n",
    "mask = df_final[\"miss\"] == True\n",
    "miss = df_final[mask]\n",
    "miss_imgs = miss[\"base64\"].tolist()\n",
    "miss_ai_labels = miss[\"ai_label\"].tolist()\n",
    "\n",
    "\n",
    "for base64_image, ai_label in zip(miss_imgs, miss_ai_labels):\n",
    "    print(f\"AI classyfy as: {ai_label}\")\n",
    "    display_img(base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3234b4-04cf-44ac-9b4e-e63e1d646ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Escritorio de Dados - Default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
