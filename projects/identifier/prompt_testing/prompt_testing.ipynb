{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e176cff-5f5f-48a9-b8ed-4a4638860834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "import textwrap\n",
    "\n",
    "from utils.utils import normalize_cols\n",
    "from utils_sheets import save_data_in_sheets\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import basedosdados as bd\n",
    "\n",
    "\n",
    "bd.config.billing_project_id = 'rj-escritorio-dev'\n",
    "bd.config.from_file = True\n",
    "bd.__version__\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 1999\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66448f1e-84c5-4fc4-9318-79fe9cf4cf42",
   "metadata": {},
   "source": [
    "- storage images: https://console.cloud.google.com/storage/browser/datario-public/flooding_detection?project=datario\n",
    "- imagens figma: https://www.figma.com/file/Qv89NLopXS60Lqf3XfTZiN/Untitled?type=design&node-id=3-44&mode=design&t=3a4g8D4QLiDQ8f3i-0\n",
    "- langchain ref: https://python.langchain.com/docs/integrations/platforms/google\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204531c-8ca9-4c97-a767-d125233a3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_link_from_storage():\n",
    "    dataset_id = \"flooding_detection\"\n",
    "    table_id = \"classified_images\"\n",
    "    st = bd.Storage(dataset_id=dataset_id, table_id=table_id)\n",
    "    blobs = (\n",
    "        st.client[\"storage_staging\"]\n",
    "        .bucket(\"datario-public\")\n",
    "        .list_blobs(prefix=f\"{dataset_id}/{table_id}\")\n",
    "    )\n",
    "\n",
    "    url_list = []\n",
    "    for blob in blobs:\n",
    "        url = str(blob.public_url)\n",
    "        if \".\" in url.split(\"/\")[-1]:\n",
    "            url_list.append(url)\n",
    "    return url_list\n",
    "\n",
    "\n",
    "def get_urls_and_labels():\n",
    "    urls = get_image_link_from_storage()\n",
    "    labels = [\n",
    "        {\"path\": \"images_with_label/flood\", \"label\": True, \"object\": \"alagamento\"},\n",
    "        {\"path\": \"images_with_label/no_flood\", \"label\": False, \"object\": \"alagamento\"},\n",
    "    ]\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        for item in labels:\n",
    "            if item.get(\"path\") in str(url):\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"object\": item.get(\"object\"),\n",
    "                        \"label\": item.get(\"label\"),\n",
    "                        \"image_url\": url,\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def balance_and_sample(df, N):\n",
    "    # Get the minimum count of the two labels\n",
    "    min_count = min(df[\"label\"].value_counts())\n",
    "\n",
    "    # Balance the DataFrame\n",
    "    df_balanced = pd.concat(\n",
    "        [df[df[\"label\"] == True].head(min_count), df[df[\"label\"] == False].head(min_count)]\n",
    "    )\n",
    "    df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "    # Sample N rows\n",
    "    if N > len(df_balanced):\n",
    "        print(\n",
    "            f\"Requested number of samples ({N}) is more than the available balanced dataset size ({len(df_balanced)}).\"\n",
    "        )\n",
    "        return df_balanced\n",
    "    return df_balanced.head(N)\n",
    "\n",
    "\n",
    "# OpenAI API Key\n",
    "\n",
    "\n",
    "def get_image_from_url(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    img.thumbnail((640, 480))\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_ai_label(response):\n",
    "    if response.get(\"error\"):\n",
    "        return \"Error\"\n",
    "    else:\n",
    "        # r = response['choices'][0]['message']['content']\n",
    "        json_string = r.replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "        json_object = json.loads(json_string)\n",
    "        return json_object[\"label\"]\n",
    "\n",
    "\n",
    "def get_ai_label_gemini(response):\n",
    "    if type(response) == tuple:\n",
    "        response = response[0]\n",
    "    json_string = str(response).replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "    json_object = json.loads(json_string)\n",
    "    return json_object[\"label\"]\n",
    "\n",
    "\n",
    "def gemini_pro_vision_classify_image(image):\n",
    "    prompt = \"\"\"\n",
    "            \"You are an expert flooding detector. You are\n",
    "            given a image. You must detect if there is flooding in the image. The output MUST\n",
    "            be a JSON object with a boolean value for the key \"\"label\"\". If you don't\n",
    "            know what to anwser, you can set the key \"\"label\"\" as false. Example:\n",
    "            {\n",
    "                \"\"label\"\": true\n",
    "            }\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-pro-vision\")\n",
    "        responses = model.generate_content(\n",
    "            contents=[prompt, image],\n",
    "            generation_config={\n",
    "                \"max_output_tokens\": 2048,\n",
    "                \"temperature\": 0.4,\n",
    "                \"top_p\": 1,\n",
    "                \"top_k\": 32,\n",
    "            },\n",
    "            stream=True,\n",
    "        )\n",
    "        responses.resolve()\n",
    "        return (responses.text, True, None)\n",
    "    except Exception as e:\n",
    "        return (' {\\n  \"label\": false\\n}', False, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54135f28-635a-41df-b78c-f27dc18f9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, chat_models\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "def get_parser():\n",
    "    # Define the structure of each item in the output\n",
    "    class OutputItem(BaseModel):\n",
    "        object: str = Field(description=\"The object identified in the image\")\n",
    "        image_descrition: str = Field(\n",
    "            description=\"Label indicating the condition or characteristic of the object\"\n",
    "        )\n",
    "        label_explanation: str = Field(description=\"Thought process explanation\")\n",
    "        label: Union[bool, str] = Field(description=\"Image description and visual elements\")\n",
    "\n",
    "    # Define the structure for the list of items\n",
    "    class OutputList(BaseModel):\n",
    "        response: List[OutputItem]\n",
    "\n",
    "    # Create the output parser using the Pydantic model\n",
    "    output_parser = PydanticOutputParser(pydantic_object=OutputList)\n",
    "\n",
    "    # Valid JSON string\n",
    "    output_example_str = \"\"\"\n",
    "    {\n",
    "        \"response\":[\n",
    "            {\n",
    "                \"object\": \"puddling_road\", \n",
    "                \"image_descrition\":\"<Insert the Image descriptin and visual elements process here>\",\n",
    "                \"label_explanation\": \"<Insert the Thought process here>\",  \n",
    "                \"label\": true\n",
    "            },\n",
    "            {\n",
    "                \"object\": \"traffic_ease_vehicle\", \n",
    "                \"image_descrition\":\"<Insert the Image description and visual elements here>\",\n",
    "                \"label_explanation\": \"<Insert the Thought process here>\",  \n",
    "                \"label\": \"easy\"\n",
    "            }\n",
    "                \n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    output_example_str = textwrap.dedent(output_example_str)\n",
    "\n",
    "    output_example = output_parser.parse(output_example_str)\n",
    "\n",
    "    return output_parser, json.dumps(output_example.dict(), indent=4)\n",
    "\n",
    "\n",
    "def get_content():\n",
    "    output_parser, output_example = get_parser()\n",
    "\n",
    "    content = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": (\n",
    "                \"\"\"\n",
    "                You are a highly skilled AI in visual analysis with expertise in interpreting water levels from CCTV images. Your task is to conduct a detailed analysis of the provided image. You will analyze and classify the road conditions based on the presence of water, focusing on the ease of traffic flow and the detection of puddles. There are four categories for your analysis:\n",
    "\n",
    "                **Thought Process:**\n",
    "\n",
    "                - **Easy Traffic (No or Small Puddling):**\n",
    "                    - Criteria: Minimal or no water on the road. Natural elements like lakes and rivers or park fountain.\n",
    "                    - Classification: `traffic_ease_vehicle: easy`, `puddling_road: false`.\n",
    "                    - Identification Guide: Look for clear, dry, or slightly wet road surfaces and small, manageable puddles.\n",
    "\n",
    "                - **Moderate Traffic (Big Size Puddling):**\n",
    "                    - Criteria: Presence of significant, larger puddles.\n",
    "                    - Classification: `traffic_ease_vehicle: moderate`, `puddling_road: true`.\n",
    "                    - Identification Guide: Detect larger puddles that could cause minor traffic disruptions but are still navigable for most vehicles.\n",
    "\n",
    "                - **Difficult Traffic (Road Partially Water Covered):**\n",
    "                    - Criteria: A partial portion of the road is covered with medium water level.\n",
    "                    - Classification: `traffic_ease_vehicle: difficult`, `puddling_road: true`.\n",
    "                    - Identification Guide: Identify areas where water coverage is extensive and high, causing notable hindrance to vehicle.\n",
    "\n",
    "                - **Impossible Traffic (Road Completely Water Covered):**\n",
    "                    - Criteria: Complete submergence of the road with high water level.\n",
    "                    - Classification: `traffic_ease_vehicle: impossible`, `puddling_road: true`.\n",
    "                    - Example: Identify a scenarios where the road is entirely submerged/flooded, making it completely impassable for vehicles.\n",
    "\n",
    "                **Input:**\n",
    "                A CCTV image.\n",
    "\n",
    "                **Output:**\n",
    "                Format the output as a JSON instance following the provided schema.\n",
    "\n",
    "                **Output Schema:**\n",
    "                \n",
    "                \"\"\"\n",
    "                + output_parser.get_format_instructions()\n",
    "                + \"\"\"\n",
    "                \n",
    "                **Example Output:**\n",
    "                \n",
    "                \"\"\"\n",
    "                + output_example\n",
    "                + \"\\nNow classify the image bellow:\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for d in content:\n",
    "        for key, value in d.items():\n",
    "            d[key] = textwrap.dedent(value)\n",
    "\n",
    "    return content\n",
    "\n",
    "\n",
    "def gemini_pro_vision_langchain(\n",
    "    image_url, content, max_output_token=300, temperature=0.4, top_k=32, top_p=1\n",
    "):\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-pro-vision\",\n",
    "        google_api_key=GOOGLE_API_KEY,\n",
    "        max_output_token=max_output_token,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "\n",
    "    message = HumanMessage(content=content + [{\"type\": \"image_url\", \"image_url\": image_url}])\n",
    "    return llm.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3693d-cf6e-4988-98c3-4503db2aba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_from_path(url_path):\n",
    "    urls = get_image_link_from_storage()\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        if url_path in str(url):\n",
    "            data.append(\n",
    "                {\n",
    "                    \"image_url\": url,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# df = get_urls_from_path(url_path=\"images_predicted_as_flood\")\n",
    "df = get_urls_from_path(url_path=\"/\")\n",
    "\n",
    "experiment_name = \"test-puddling-criteria\"\n",
    "experiment_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "content = get_content()\n",
    "max_output_token = 1000\n",
    "temperature = 0.4\n",
    "top_k = 32\n",
    "top_p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b47a46-398f-4114-85d4-684752ccac6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "predictions_path = Path(f\"./data/predictions/{experiment_name}__{experiment_datetime}.csv\")\n",
    "\n",
    "if predictions_path.exists():\n",
    "    predictions = pd.read_csv(predictions_path)\n",
    "    predictions_list = predictions[\"image_url\"].tolist()\n",
    "else:\n",
    "    predictions_list = []\n",
    "\n",
    "output_parser, output_example = get_parser()\n",
    "\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    image_url = row[\"image_url\"]\n",
    "    if image_url not in predictions_list:\n",
    "        response = gemini_pro_vision_langchain(\n",
    "            image_url=image_url,\n",
    "            content=content,\n",
    "            max_output_token=max_output_token,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "        )\n",
    "        response_parsed = output_parser.parse(response.content)\n",
    "        response_parsed = response_parsed.dict()\n",
    "\n",
    "        print(f\"{index} - {len(df)}\")\n",
    "        print(json.dumps(response_parsed, indent=4))\n",
    "        display(get_image_from_url(image_url))\n",
    "\n",
    "        save_data_in_sheets(\n",
    "            save_data=True,\n",
    "            data={\n",
    "                \"content\": get_content(),\n",
    "                \"max_output_token\": max_output_token,\n",
    "                \"temperature\": temperature,\n",
    "                \"top_k\": top_k,\n",
    "                \"top_p\": top_p,\n",
    "                \"experiment_name\": experiment_name,\n",
    "                \"experiment_datetime\": experiment_datetime,\n",
    "                \"true_object\": \"\",\n",
    "                \"response\": response_parsed.get(\"response\", \"\"),\n",
    "                \"image_url\": image_url,\n",
    "                \"image\": f'=IMAGE(\"{image_url}\")',\n",
    "            },\n",
    "            data_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=436224340\",\n",
    "            content_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=1779223884\",\n",
    "        )\n",
    "\n",
    "        pd.DataFrame([{\"image_url\": image_url}]).to_csv(\n",
    "            path_or_buf=predictions_path,\n",
    "            index=False,\n",
    "            header=not predictions_path.exists(),\n",
    "            mode=\"a\",\n",
    "        )\n",
    "    else:\n",
    "        print(f\"{index} - {len(df)}: already predicted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d16a90-cc28-4639-a7ef-b491fd37d0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35215f-8f6d-4b8a-98f3-5c7ef1c7ff5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e012c-8c4e-42d6-a915-9c04de0ae0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f459c94-045e-477d-9e2d-4daae12c3a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557a65b-d976-43d2-ae29-fadba8336f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e416e7-f770-4758-80c1-616e788e4d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b1675-9ed5-41a3-96de-ea07b5a17cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ad56f-48c0-493c-8010-2d477f75e015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a93eef-6414-40ca-a260-05b363514053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4d874-13f5-4fc5-9535-2ceb4f35c6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363487d0-abf1-4810-bd4e-af6ecdc9bd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef2392-2b12-4b5f-adbb-d7ac8808a183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0981861-bf78-4313-9707-78fbeed07676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f41b9-72f9-4ff4-a92b-90467f0d6985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25eb26-86d0-4fbd-baed-32eea8413c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8eb834-0fda-43a1-a48d-38ccfc620cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249ce22-8953-425f-b048-3799f4132320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f633618-b120-46a9-bebf-571115518247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a583ac5-28e6-4172-8254-87fcbba4dcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af26c7-c932-44fc-8ff6-06bfd9449586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63777b1b-9c46-4d4e-81e9-02f8434ce218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320dc68c-282d-42e0-8560-d7efd730678d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8311f0e-d371-431d-87bf-a12cb150c6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f66e1-9636-4e51-9818-a74ac476259a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5aaa57-c42b-4a9d-a641-2fac9f04a490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e727eb-a617-4360-863e-aeb2b16af3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8072c17-f764-4091-98bd-e9a7e04ecb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948454c4-478a-42b2-8888-c0ee53604edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c131bba-ce3d-4166-b29b-da2209dfa26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65073a69-14c4-429e-8f54-77216854c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "true_values = df_final[\"flood\"].tolist()\n",
    "predicted_values = df_final[\"ai_label\"].tolist()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_values, predicted_values)\n",
    "precision = precision_score(true_values, predicted_values, pos_label=True)\n",
    "recall = recall_score(true_values, predicted_values, pos_label=True)\n",
    "f1 = f1_score(true_values, predicted_values, pos_label=True)\n",
    "conf_matrix = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"False\", \"True\"],\n",
    "    yticklabels=[\"False\", \"True\"],\n",
    ")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# resize_factor = 3\n",
    "# imgs = 10\n",
    "# time = 1:00\n",
    "# Accuracy: 0.7\n",
    "# Precision: 0.6666666666666666\n",
    "# Recall: 0.5\n",
    "# F1 Score: 0.5714285714285715\n",
    "\n",
    "# resize_factor = 1\n",
    "# imgs = 10\n",
    "# time = 1:15\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75\n",
    "\n",
    "\n",
    "# resize_factor = 5\n",
    "# imgs = 10\n",
    "# time = 1:20\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc24eb2-79a9-4008-a62d-68352822cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"miss\"] = np.where(df_final[\"flood\"] == df_final[\"ai_label\"], False, True)\n",
    "mask = df_final[\"miss\"] == True\n",
    "miss = df_final[mask]\n",
    "miss_imgs = miss[\"base64\"].tolist()\n",
    "miss_ai_labels = miss[\"ai_label\"].tolist()\n",
    "\n",
    "\n",
    "for base64_image, ai_label in zip(miss_imgs, miss_ai_labels):\n",
    "    print(f\"AI classyfy as: {ai_label}\")\n",
    "    display_img(base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3234b4-04cf-44ac-9b4e-e63e1d646ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Escritorio de Dados - Default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
