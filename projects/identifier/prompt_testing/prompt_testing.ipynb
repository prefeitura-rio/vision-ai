{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e176cff-5f5f-48a9-b8ed-4a4638860834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "\n",
    "import textwrap\n",
    "\n",
    "from utils.utils import normalize_cols\n",
    "from utils_sheets import save_data_in_sheets\n",
    "import base64\n",
    "import requests\n",
    "import json\n",
    "import io\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "import random\n",
    "import datetime\n",
    "import glob\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import basedosdados as bd\n",
    "\n",
    "\n",
    "bd.config.billing_project_id = 'rj-escritorio-dev'\n",
    "bd.config.from_file = True\n",
    "bd.__version__\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 1999\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66448f1e-84c5-4fc4-9318-79fe9cf4cf42",
   "metadata": {},
   "source": [
    "- storage images: https://console.cloud.google.com/storage/browser/datario-public/flooding_detection?project=datario\n",
    "- imagens figma: https://www.figma.com/file/Qv89NLopXS60Lqf3XfTZiN/Untitled?type=design&node-id=3-44&mode=design&t=3a4g8D4QLiDQ8f3i-0\n",
    "- langchain ref: https://python.langchain.com/docs/integrations/platforms/google\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204531c-8ca9-4c97-a767-d125233a3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_link_from_storage():\n",
    "    dataset_id = \"flooding_detection\"\n",
    "    table_id = \"classified_images\"\n",
    "    st = bd.Storage(dataset_id=dataset_id, table_id=table_id)\n",
    "    blobs = (\n",
    "        st.client[\"storage_staging\"]\n",
    "        .bucket(\"datario-public\")\n",
    "        .list_blobs(prefix=f\"{dataset_id}/{table_id}\")\n",
    "    )\n",
    "\n",
    "    url_list = []\n",
    "    for blob in blobs:\n",
    "        url = str(blob.public_url)\n",
    "        if \".\" in url.split(\"/\")[-1]:\n",
    "            url_list.append(url)\n",
    "    return url_list\n",
    "\n",
    "\n",
    "def get_urls_and_labels():\n",
    "    urls = get_image_link_from_storage()\n",
    "    labels = [\n",
    "        {\"path\": \"images_with_label/flood\", \"label\": True, \"object\": \"alagamento\"},\n",
    "        {\"path\": \"images_with_label/no_flood\", \"label\": False, \"object\": \"alagamento\"},\n",
    "    ]\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        for item in labels:\n",
    "            if item.get(\"path\") in str(url):\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"object\": item.get(\"object\"),\n",
    "                        \"label\": item.get(\"label\"),\n",
    "                        \"image_url\": url,\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def balance_and_sample(df, N):\n",
    "    # Get the minimum count of the two labels\n",
    "    min_count = min(df[\"label\"].value_counts())\n",
    "\n",
    "    # Balance the DataFrame\n",
    "    df_balanced = pd.concat(\n",
    "        [df[df[\"label\"] == True].head(min_count), df[df[\"label\"] == False].head(min_count)]\n",
    "    )\n",
    "    df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "    # Sample N rows\n",
    "    if N > len(df_balanced):\n",
    "        print(\n",
    "            f\"Requested number of samples ({N}) is more than the available balanced dataset size ({len(df_balanced)}).\"\n",
    "        )\n",
    "        return df_balanced\n",
    "    return df_balanced.head(N)\n",
    "\n",
    "\n",
    "# OpenAI API Key\n",
    "\n",
    "\n",
    "def get_image_from_url(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    img.thumbnail((640, 480))\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_ai_label(response):\n",
    "    if response.get(\"error\"):\n",
    "        return \"Error\"\n",
    "    else:\n",
    "        # r = response['choices'][0]['message']['content']\n",
    "        json_string = r.replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "        json_object = json.loads(json_string)\n",
    "        return json_object[\"label\"]\n",
    "\n",
    "\n",
    "def get_ai_label_gemini(response):\n",
    "    if type(response) == tuple:\n",
    "        response = response[0]\n",
    "    json_string = str(response).replace(\"```json\\n\", \"\").replace(\"\\n```\", \"\")\n",
    "    json_object = json.loads(json_string)\n",
    "    return json_object[\"label\"]\n",
    "\n",
    "\n",
    "def gemini_pro_vision_classify_image(image):\n",
    "    prompt = \"\"\"\n",
    "            \"You are an expert flooding detector. You are\n",
    "            given a image. You must detect if there is flooding in the image. The output MUST\n",
    "            be a JSON object with a boolean value for the key \"\"label\"\". If you don't\n",
    "            know what to anwser, you can set the key \"\"label\"\" as false. Example:\n",
    "            {\n",
    "                \"\"label\"\": true\n",
    "            }\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "        model = genai.GenerativeModel(\"gemini-pro-vision\")\n",
    "        responses = model.generate_content(\n",
    "            contents=[prompt, image],\n",
    "            generation_config={\n",
    "                \"max_output_tokens\": 2048,\n",
    "                \"temperature\": 0.4,\n",
    "                \"top_p\": 1,\n",
    "                \"top_k\": 32,\n",
    "            },\n",
    "            stream=True,\n",
    "        )\n",
    "        responses.resolve()\n",
    "        return (responses.text, True, None)\n",
    "    except Exception as e:\n",
    "        return (' {\\n  \"label\": false\\n}', False, str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0a32f-5bf6-403c-a136-ae15e2a625fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54135f28-635a-41df-b78c-f27dc18f9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, chat_models\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "def get_parser():\n",
    "    # Define the structure of each item in the output\n",
    "    class OutputItem(BaseModel):\n",
    "        object: str = Field(description=\"The object identified in the image\")\n",
    "        label_explanation: str = Field(\n",
    "            description=\"Highly detailed visual description of the image given the object context\"\n",
    "        )\n",
    "        label: Union[bool, str] = Field(\n",
    "            description=\"Label indicating the condition or characteristic of the object\"\n",
    "        )\n",
    "\n",
    "    # Define the structure for the list of items\n",
    "    class OutputList(BaseModel):\n",
    "        image_description: str = Field(\n",
    "            description=\"Image description and visual elements from identification_guide column\"\n",
    "        )\n",
    "        objects: List[OutputItem]\n",
    "\n",
    "    # Create the output parser using the Pydantic model\n",
    "    output_parser = PydanticOutputParser(pydantic_object=OutputList)\n",
    "\n",
    "    # Valid JSON string\n",
    "    output_example_str = \"\"\"\n",
    "    {\n",
    "        \"image_description\":\"<Insert the Image description and visual elements here>\",\n",
    "        \"objects\":[\n",
    "            {\n",
    "                \"object\": \"<Object from objects table>\", \n",
    "                \"label_explanation\": \"<Visual description of the image given the object context>\",  \n",
    "                \"label\": \"<Respective label from object in objects table>\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    output_example_str = textwrap.dedent(output_example_str)\n",
    "\n",
    "    output_example = output_parser.parse(output_example_str)\n",
    "\n",
    "    return output_parser, json.dumps(output_example.dict(), indent=4)\n",
    "\n",
    "\n",
    "def get_content():\n",
    "\n",
    "    output_parser, output_example = get_parser()\n",
    "    prompt_table = get_prompt_table(\n",
    "        url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=1672006844\"\n",
    "    )\n",
    "    output_schema = json.dumps(json.loads(output_parser.pydantic_object.schema_json()), indent=4)\n",
    "    content = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": (\n",
    "                f\"\"\"\n",
    "                You are a highly skilled CCTV camera operator. Your task is to conduct a detailed analysis of the provided image. Analyze, classify, and describe the visual features of objects given an objects table. Ensure that every object from the objects table has at least one entry in the output with the respective label given the criteria and identification_guide.\n",
    "                \n",
    "                **Objects Table**\n",
    "                \n",
    "                {prompt_table}\n",
    "                  \n",
    "                **Thought Process**\n",
    "\n",
    "                    1. Begin by providing a highly detailed description of the image and fill the image_description output.\n",
    "                    2. Use the criteria and identification_guide as context to describe the visual features of each object and fill the label_explanation output. Do not copy the criteria and identification_guide; just use them as context to give a highly detailed visual description of label_explanation.\n",
    "                    3. Then, using the label_explanation, select the most accurate label for each object. \n",
    "                    4. Ensure that every object from the objects table has at least one entry in the output with the respective label.\n",
    "                    5. Return the output.    \n",
    "\n",
    "\n",
    "                **Input:**\n",
    "                A CCTV image.\n",
    "\n",
    "                **Output:**\n",
    "                Format the output as a JSON instance following the provided schema. \n",
    "\n",
    "                **Output Schema:**\n",
    "                \n",
    "                ```json\n",
    "                {output_schema}\n",
    "                ```\n",
    "                \n",
    "                **Example Output:**\n",
    "                \n",
    "                ```json\n",
    "                {output_example}\n",
    "                ```\n",
    "                \n",
    "                Now classify the image bellow:\n",
    "                \"\"\"\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for d in content:\n",
    "        for key, value in d.items():\n",
    "            d[key] = textwrap.dedent(value.replace(\"                \", \"\"))\n",
    "    return content\n",
    "\n",
    "\n",
    "def get_prompt_table(url: str):\n",
    "    request_url = url.replace(\"edit#gid=\", \"export?format=csv&gid=\")\n",
    "    response = requests.get(request_url)\n",
    "    return pd.read_csv(io.StringIO(response.content.decode(\"utf-8\"))).to_markdown(index=False)\n",
    "\n",
    "\n",
    "def gemini_pro_vision_langchain(\n",
    "    image_url, content, max_output_token=300, temperature=0.4, top_k=32, top_p=1\n",
    "):\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-pro-vision\",\n",
    "        google_api_key=GOOGLE_API_KEY,\n",
    "        max_output_token=max_output_token,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "\n",
    "    message = HumanMessage(content=content + [{\"type\": \"image_url\", \"image_url\": image_url}])\n",
    "    return llm.invoke([message])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3693d-cf6e-4988-98c3-4503db2aba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "def get_urls_from_path(url_path):\n",
    "    urls = get_image_link_from_storage()\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        if url_path in str(url):\n",
    "            data.append(\n",
    "                {\n",
    "                    \"image_url\": url,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# df = get_urls_from_path(url_path=\"images_predicted_as_flood\")\n",
    "df = get_urls_from_path(url_path=\"/\")\n",
    "# content = get_content()\n",
    "experiment_name = \"test-road-blockade\"\n",
    "\n",
    "experiment_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "content = get_content()\n",
    "max_output_token = 2000\n",
    "temperature = 0.1\n",
    "top_k = 32\n",
    "top_p = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d1d2d-1c56-42c1-ac24-791a2479302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(Markdown(content[0]['text']))\n",
    "# print(content[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b47a46-398f-4114-85d4-684752ccac6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "predictions_path = Path(f\"./data/predictions/{experiment_name}__{experiment_datetime}.csv\")\n",
    "\n",
    "if predictions_path.exists():\n",
    "    predictions = pd.read_csv(predictions_path)\n",
    "    predictions_list = predictions[\"image_url\"].tolist()\n",
    "else:\n",
    "    predictions_list = []\n",
    "\n",
    "output_parser, output_example = get_parser()\n",
    "\n",
    "retry = 5\n",
    "for index, row in df.iterrows():\n",
    "    image_url = row[\"image_url\"]\n",
    "    retry_count = 0\n",
    "    while retry_count <= retry:\n",
    "        try:\n",
    "            if image_url not in predictions_list:\n",
    "                response = gemini_pro_vision_langchain(\n",
    "                    image_url=image_url,\n",
    "                    content=content,\n",
    "                    max_output_token=max_output_token,\n",
    "                    temperature=temperature,\n",
    "                    top_k=top_k,\n",
    "                    top_p=top_p,\n",
    "                )\n",
    "\n",
    "                response_parsed = output_parser.parse(response.content)\n",
    "                response_parsed = response_parsed.dict()\n",
    "\n",
    "                print(f\"{index} - {len(df)}\")\n",
    "                # print(json.dumps(response_parsed, indent=4))\n",
    "                # display(get_image_from_url(image_url))\n",
    "\n",
    "                save_data_in_sheets(\n",
    "                    save_data=True,\n",
    "                    data={\n",
    "                        \"content\": get_content(),\n",
    "                        \"max_output_token\": max_output_token,\n",
    "                        \"temperature\": temperature,\n",
    "                        \"top_k\": top_k,\n",
    "                        \"top_p\": top_p,\n",
    "                        \"experiment_name\": experiment_name,\n",
    "                        \"experiment_datetime\": experiment_datetime,\n",
    "                        \"true_object\": \"\",\n",
    "                        \"response\": response_parsed,\n",
    "                        \"image_url\": image_url,\n",
    "                        \"image\": f'=IMAGE(\"{image_url}\")',\n",
    "                    },\n",
    "                    data_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=436224340\",\n",
    "                    content_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=1779223884\",\n",
    "                )\n",
    "\n",
    "                pd.DataFrame([{\"image_url\": image_url}]).to_csv(\n",
    "                    path_or_buf=predictions_path,\n",
    "                    index=False,\n",
    "                    header=not predictions_path.exists(),\n",
    "                    mode=\"a\",\n",
    "                )\n",
    "            else:\n",
    "                print(f\"{index} - {len(df)}: already predicted\")\n",
    "\n",
    "            retry_count = retry + 1\n",
    "        except Exception as e:\n",
    "            print(f\"{index} - {len(df)}: Error\\n {e}\\n\\n\\nAI Response:\")\n",
    "\n",
    "            print(response.content)\n",
    "\n",
    "            retry_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35215f-8f6d-4b8a-98f3-5c7ef1c7ff5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e012c-8c4e-42d6-a915-9c04de0ae0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f459c94-045e-477d-9e2d-4daae12c3a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557a65b-d976-43d2-ae29-fadba8336f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e416e7-f770-4758-80c1-616e788e4d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b1675-9ed5-41a3-96de-ea07b5a17cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ad56f-48c0-493c-8010-2d477f75e015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a93eef-6414-40ca-a260-05b363514053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4d874-13f5-4fc5-9535-2ceb4f35c6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363487d0-abf1-4810-bd4e-af6ecdc9bd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef2392-2b12-4b5f-adbb-d7ac8808a183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0981861-bf78-4313-9707-78fbeed07676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f41b9-72f9-4ff4-a92b-90467f0d6985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25eb26-86d0-4fbd-baed-32eea8413c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8eb834-0fda-43a1-a48d-38ccfc620cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249ce22-8953-425f-b048-3799f4132320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f633618-b120-46a9-bebf-571115518247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a583ac5-28e6-4172-8254-87fcbba4dcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af26c7-c932-44fc-8ff6-06bfd9449586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63777b1b-9c46-4d4e-81e9-02f8434ce218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320dc68c-282d-42e0-8560-d7efd730678d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8311f0e-d371-431d-87bf-a12cb150c6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f66e1-9636-4e51-9818-a74ac476259a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5aaa57-c42b-4a9d-a641-2fac9f04a490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e727eb-a617-4360-863e-aeb2b16af3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8072c17-f764-4091-98bd-e9a7e04ecb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948454c4-478a-42b2-8888-c0ee53604edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c131bba-ce3d-4166-b29b-da2209dfa26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65073a69-14c4-429e-8f54-77216854c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "true_values = df_final[\"flood\"].tolist()\n",
    "predicted_values = df_final[\"ai_label\"].tolist()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_values, predicted_values)\n",
    "precision = precision_score(true_values, predicted_values, pos_label=True)\n",
    "recall = recall_score(true_values, predicted_values, pos_label=True)\n",
    "f1 = f1_score(true_values, predicted_values, pos_label=True)\n",
    "conf_matrix = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"False\", \"True\"],\n",
    "    yticklabels=[\"False\", \"True\"],\n",
    ")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# resize_factor = 3\n",
    "# imgs = 10\n",
    "# time = 1:00\n",
    "# Accuracy: 0.7\n",
    "# Precision: 0.6666666666666666\n",
    "# Recall: 0.5\n",
    "# F1 Score: 0.5714285714285715\n",
    "\n",
    "# resize_factor = 1\n",
    "# imgs = 10\n",
    "# time = 1:15\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75\n",
    "\n",
    "\n",
    "# resize_factor = 5\n",
    "# imgs = 10\n",
    "# time = 1:20\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc24eb2-79a9-4008-a62d-68352822cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"miss\"] = np.where(df_final[\"flood\"] == df_final[\"ai_label\"], False, True)\n",
    "mask = df_final[\"miss\"] == True\n",
    "miss = df_final[mask]\n",
    "miss_imgs = miss[\"base64\"].tolist()\n",
    "miss_ai_labels = miss[\"ai_label\"].tolist()\n",
    "\n",
    "\n",
    "for base64_image, ai_label in zip(miss_imgs, miss_ai_labels):\n",
    "    print(f\"AI classyfy as: {ai_label}\")\n",
    "    display_img(base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77779a-d488-4f08-8aea-52394f9741e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ef146-77b9-4969-bce0-c27dc606059b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b32695b-c8a0-46d8-a5e4-2121f88ac158",
   "metadata": {},
   "source": [
    "You are a highly skilled prompt engineering focus in create prompts for CCTV image recognition. Your task is to optimize and refine a provided example prompt.\n",
    "\n",
    "you output is a diff between the provided prompt and the new optmized prompt\n",
    "\n",
    "shall we start?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b74ec-93a9-4328-862f-54c3f1162e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Escritorio de Dados - Default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
