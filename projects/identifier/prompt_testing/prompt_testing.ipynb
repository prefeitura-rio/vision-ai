{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e176cff-5f5f-48a9-b8ed-4a4638860834",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import base64\n",
    "import datetime\n",
    "import io\n",
    "import json\n",
    "import sys\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "from typing import List, Union\n",
    "\n",
    "import basedosdados as bd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import google.generativeai as genai\n",
    "from langchain import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, chat_models\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from IPython.display import Markdown\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "sys.path.insert(0, \"../../\")\n",
    "from utils_sheets import save_data_in_sheets\n",
    "\n",
    "bd.config.billing_project_id = 'rj-escritorio-dev'\n",
    "bd.config.from_file = True\n",
    "bd.__version__\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 1999\n",
    "pd.options.display.max_colwidth = 200\n",
    "\n",
    "\n",
    "from vision_ai_api import APIVisionAI\n",
    "\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel, Part\n",
    "# GOOGLE_API_KEY = \"\"\n",
    "PROJECT_ID = \"rj-escritorio-dev\"\n",
    "LOCATION = \"us-central1\"\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66448f1e-84c5-4fc4-9318-79fe9cf4cf42",
   "metadata": {},
   "source": [
    "- storage images: https://console.cloud.google.com/storage/browser/datario-public/flooding_detection?project=datario\n",
    "- imagens figma: https://www.figma.com/file/Qv89NLopXS60Lqf3XfTZiN/Untitled?type=design&node-id=3-44&mode=design&t=3a4g8D4QLiDQ8f3i-0\n",
    "- langchain ref: https://python.langchain.com/docs/integrations/platforms/google\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204531c-8ca9-4c97-a767-d125233a3587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_link_from_storage():\n",
    "    dataset_id = \"flooding_detection\"\n",
    "    table_id = \"classified_images\"\n",
    "    st = bd.Storage(dataset_id=dataset_id, table_id=table_id)\n",
    "    blobs = (\n",
    "        st.client[\"storage_staging\"]\n",
    "        .bucket(\"datario-public\")\n",
    "        .list_blobs(prefix=f\"{dataset_id}/{table_id}\")\n",
    "    )\n",
    "\n",
    "    url_list = []\n",
    "    for blob in blobs:\n",
    "        url = str(blob.public_url)\n",
    "        if \".\" in url.split(\"/\")[-1]:\n",
    "            url_list.append(url)\n",
    "    return url_list\n",
    "\n",
    "\n",
    "def get_urls_and_labels():\n",
    "    urls = get_image_link_from_storage()\n",
    "    labels = [\n",
    "        {\"path\": \"images_with_label/flood\", \"label\": True, \"object\": \"alagamento\"},\n",
    "        {\"path\": \"images_with_label/no_flood\", \"label\": False, \"object\": \"alagamento\"},\n",
    "    ]\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        for item in labels:\n",
    "            if item.get(\"path\") in str(url):\n",
    "                data.append(\n",
    "                    {\n",
    "                        \"object\": item.get(\"object\"),\n",
    "                        \"label\": item.get(\"label\"),\n",
    "                        \"image_url\": url,\n",
    "                    }\n",
    "                )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "def balance_and_sample(df, N):\n",
    "    # Get the minimum count of the two labels\n",
    "    min_count = min(df[\"label\"].value_counts())\n",
    "\n",
    "    # Balance the DataFrame\n",
    "    df_balanced = pd.concat(\n",
    "        [df[df[\"label\"] == True].head(min_count), df[df[\"label\"] == False].head(min_count)]\n",
    "    )\n",
    "    df_balanced = df_balanced.sample(frac=1).reset_index(drop=True)\n",
    "    # Sample N rows\n",
    "    if N > len(df_balanced):\n",
    "        print(\n",
    "            f\"Requested number of samples ({N}) is more than the available balanced dataset size ({len(df_balanced)}).\"\n",
    "        )\n",
    "        return df_balanced\n",
    "    return df_balanced.head(N)\n",
    "\n",
    "\n",
    "def get_image_from_url(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(io.BytesIO(response.content))\n",
    "    img.thumbnail((640, 480))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7435ba-b2b2-4e56-a3b3-3597593f366a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54135f28-635a-41df-b78c-f27dc18f9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain import PromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI, chat_models\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "\n",
    "class Object(BaseModel):\n",
    "    object: str = Field(description=\"The object from the objects table\")\n",
    "    label_explanation: str = Field(\n",
    "        description=\"Highly detailed visual description of the image given the object context\"\n",
    "    )\n",
    "    label: Union[bool, str, None] = Field(\n",
    "        description=\"Label indicating the condition or characteristic of the object\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ObjectFactory:\n",
    "    @classmethod\n",
    "    def generate_sample(cls) -> Object:\n",
    "        return Object(\n",
    "            object=\"<Object from objects table>\",\n",
    "            label_explanation=\"<Visual description of the image given the object context>\",\n",
    "            label=\"<Selected label from objects table>\",\n",
    "        )\n",
    "\n",
    "\n",
    "class Output(BaseModel):\n",
    "    objects: List[Object]\n",
    "\n",
    "\n",
    "class OutputFactory:\n",
    "    @classmethod\n",
    "    def generate_sample(cls) -> Output:\n",
    "        return Output(objects=[ObjectFactory.generate_sample()])\n",
    "\n",
    "\n",
    "class OutputFactory:\n",
    "    @classmethod\n",
    "    def generate_sample(cls) -> Output:\n",
    "        return Output(objects=[ObjectFactory.generate_sample()])\n",
    "\n",
    "\n",
    "def get_parser():\n",
    "\n",
    "    # Create the output parser using the Pydantic model\n",
    "    output_parser = PydanticOutputParser(pydantic_object=Output)\n",
    "\n",
    "    # Valid JSON string\n",
    "    output_example_str = str(OutputFactory().generate_sample().dict()).replace(\"'\", '\"')\n",
    "\n",
    "    output_example_str = textwrap.dedent(output_example_str)\n",
    "    output_example = output_parser.parse(output_example_str)\n",
    "    output_example_parsed = json.dumps(output_example.dict(), indent=4)\n",
    "\n",
    "    output_schema = json.loads(output_parser.pydantic_object.schema_json())\n",
    "    output_schema_parsed = json.dumps(output_schema, indent=4)\n",
    "\n",
    "    return output_parser, output_schema_parsed, output_example_parsed\n",
    "\n",
    "\n",
    "def get_objects_table(\n",
    "    url: str = \"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=1672006844\",\n",
    "):\n",
    "    request_url = url.replace(\"edit#gid=\", \"export?format=csv&gid=\")\n",
    "    response = requests.get(request_url)\n",
    "    dataframe = pd.read_csv(io.StringIO(response.content.decode(\"utf-8\")), dtype=str)\n",
    "    dataframe[\"labels\"] = dataframe[\"labels\"].fillna(\"null\")\n",
    "    objects_table_md = dataframe.to_markdown(index=False)\n",
    "    objects_labels = (\n",
    "        dataframe[[\"object\", \"labels\"]]\n",
    "        .groupby(by=[\"object\"], sort=False)[\"labels\"]\n",
    "        .apply(lambda x: \", \".join(x))\n",
    "        .reset_index()\n",
    "    )\n",
    "    objects_labels[\"labels\"] = objects_labels[\"labels\"].str.replace(\"true, false\", \"bool\")\n",
    "    objects_labels_md = objects_labels.to_markdown(index=False)\n",
    "    objects_labels_md = objects_labels_md\n",
    "    return objects_table_md, objects_labels_md\n",
    "\n",
    "\n",
    "def get_prompt():\n",
    "\n",
    "    template = \"\"\"\n",
    "                **Role:**\n",
    "\n",
    "                You are tasked with analyzing a CCTV image of Rio de Janeiro to identify potential city issues. Your analysis should focus on several key elements defined in an 'Objects Table', which includes criteria and identification guides for various objects and conditions that may impact city life. The goal is to classify these elements and provide a clear, concise description for each, enabling human CCTV operators to quickly understand and act upon the information. All objects from the 'Objects Table' MUST HAVE one entry in the output.\n",
    "\n",
    "                **Objects Table**\n",
    "\n",
    "                {objects_table_md}\n",
    "\n",
    "                **Thought Process**\n",
    "\n",
    "                    1. Use the criteria and identification_guide as context to describe the visual features of each object and fill the label_explanation output. Do not simply repeat the criteria or identification_guide but use then as context for your description.\n",
    "                    2. Based on your visual description and analysis, select the most accurate label for each object from the options provided in the 'Objects Table'. You must use only the provided  labels!\n",
    "                    3. Ensure that EVERY OBJECT from the objects table HAS ONE ENTRY in the output with the respective label and detailed description.\n",
    "                    4. Return the output.   \n",
    "\n",
    "\n",
    "                **Input:**\n",
    "                A CCTV image.\n",
    "\n",
    "                **Output:**\n",
    "\n",
    "                    - Format the output as a JSON instance following the provided schema. \n",
    "\n",
    "                **Output Schema:**\n",
    "\n",
    "\n",
    "                ```json\n",
    "                {output_schema}\n",
    "                ```\n",
    "\n",
    "\n",
    "                **Example Output:**\n",
    "\n",
    "                    - For each object analyzed, your output should resemble the following format:\n",
    "\n",
    "\n",
    "                ```json\n",
    "                {output_example}\n",
    "                ```\n",
    "\n",
    "                Now classify the image bellow:\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    template = vision_ai_api._get(\"/prompts\").get(\"items\")[0].get(\"prompt_text\")\n",
    "\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"objects_table_md\", \"output_schema\", \"output_example\"], template=template\n",
    "    )\n",
    "\n",
    "    _, output_schema, output_example = get_parser()\n",
    "    objects_table_md, _ = get_objects_table()\n",
    "\n",
    "    filled_prompt = prompt_template.format(\n",
    "        objects_table_md=objects_table_md,\n",
    "        output_schema=output_schema,\n",
    "        output_example=output_example,\n",
    "    )\n",
    "    filled_prompt = filled_prompt.replace(\"                    \", \"\")\n",
    "\n",
    "    return filled_prompt, template\n",
    "\n",
    "\n",
    "def gemini_pro_vision_langchain(\n",
    "    image_url, prompt, max_output_token=300, temperature=0.4, top_k=32, top_p=1\n",
    "):\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-pro-vision\",\n",
    "        google_api_key=GOOGLE_API_KEY,\n",
    "        max_output_token=max_output_token,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    content = [{\"type\": \"text\", \"text\": prompt}, {\"type\": \"image_url\", \"image_url\": image_url}]\n",
    "    message = HumanMessage(content=content)\n",
    "    return llm.invoke([message])\n",
    "\n",
    "\n",
    "def gemini_pro_vision_google(\n",
    "    image_url, prompt, max_output_token=300, temperature=0.4, top_k=32, top_p=1\n",
    "):\n",
    "    image_response = requests.get(image_url)\n",
    "    image = Image.open(io.BytesIO(image_response.content))\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    model = genai.GenerativeModel(\"gemini-pro-vision\")\n",
    "    responses = model.generate_content(\n",
    "        contents=[prompt, image],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": max_output_token,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_k\": top_k,\n",
    "            \"top_p\": top_p,\n",
    "        },\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    responses.resolve()\n",
    "    ai_response = responses.text\n",
    "    return ai_response\n",
    "\n",
    "\n",
    "def gemini_pro_vision_vertex(\n",
    "    image_url, prompt, max_output_token=300, temperature=0.4, top_k=32, top_p=1\n",
    "):\n",
    "    image_response = requests.get(image_url)\n",
    "    image_type = image_url.split(\".\")[-1]\n",
    "    model = GenerativeModel(\"gemini-pro-vision\")\n",
    "    responses = model.generate_content(\n",
    "        contents=[prompt, Part.from_data(image_response.content, f\"image/{image_type}\")],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": max_output_token,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_k\": top_k,\n",
    "            \"top_p\": top_p,\n",
    "        },\n",
    "    )\n",
    "    ai_response = responses.text\n",
    "    return ai_response\n",
    "\n",
    "\n",
    "def predict_and_save(\n",
    "    save_data,\n",
    "    output_parser,\n",
    "    image_url,\n",
    "    prompt,\n",
    "    max_output_token,\n",
    "    temperature,\n",
    "    top_k,\n",
    "    top_p,\n",
    "    experiment_name,\n",
    "    experiment_datetime,\n",
    "    predictions_path,\n",
    "):\n",
    "    response = gemini_pro_vision_vertex(\n",
    "        image_url=image_url,\n",
    "        prompt=prompt,\n",
    "        max_output_token=max_output_token,\n",
    "        temperature=temperature,\n",
    "        top_k=top_k,\n",
    "        top_p=top_p,\n",
    "    )\n",
    "    response_parsed = output_parser.parse(response)\n",
    "    response_parsed = response_parsed.dict()\n",
    "\n",
    "    save_data_in_sheets(\n",
    "        save_data=save_data,\n",
    "        data={\n",
    "            \"prompt\": prompt,\n",
    "            \"max_output_token\": max_output_token,\n",
    "            \"temperature\": temperature,\n",
    "            \"top_k\": top_k,\n",
    "            \"top_p\": top_p,\n",
    "            \"experiment_name\": experiment_name,\n",
    "            \"experiment_datetime\": experiment_datetime,\n",
    "            \"true_object\": \"\",\n",
    "            \"response\": response_parsed,\n",
    "            \"image_url\": image_url,\n",
    "            \"image\": f'=IMAGE(\"{image_url}\")',\n",
    "        },\n",
    "        data_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=436224340\",\n",
    "        prompt_url=\"https://docs.google.com/spreadsheets/d/122uOaPr8YdW5PTzrxSPF-FD0tgco596HqgB7WK7cHFw/edit#gid=1779223884\",\n",
    "    )\n",
    "\n",
    "    pd.DataFrame([{\"image_url\": image_url}]).to_csv(\n",
    "        path_or_buf=predictions_path,\n",
    "        index=False,\n",
    "        header=not predictions_path.exists(),\n",
    "        mode=\"a\",\n",
    "    )\n",
    "\n",
    "    return response, response_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e3693d-cf6e-4988-98c3-4503db2aba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls_from_path(url_path):\n",
    "    urls = get_image_link_from_storage()\n",
    "    data = []\n",
    "    for url in urls:\n",
    "        if url_path in str(url):\n",
    "            data.append(\n",
    "                {\n",
    "                    \"image_url\": url,\n",
    "                }\n",
    "            )\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "with open(\"secrets.json\") as f:\n",
    "    s = json.load(f)\n",
    "\n",
    "vision_ai_api = APIVisionAI(\n",
    "    username=s.get(\"username\"),\n",
    "    password=s.get(\"password\"),\n",
    ")\n",
    "\n",
    "\n",
    "# df = get_urls_from_path(url_path=\"images_predicted_as_flood\")\n",
    "df = get_urls_from_path(url_path=\"/\")\n",
    "experiment_name = \"test-object-label-table\"\n",
    "experiment_datetime = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "prompt, prompt_template = get_prompt()\n",
    "max_output_token = 2048\n",
    "temperature = 0.2\n",
    "top_k = 32\n",
    "top_p = 1\n",
    "retry = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b47a46-398f-4114-85d4-684752ccac6b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_path = Path(f\"./data/predictions/{experiment_name}__{experiment_datetime}.csv\")\n",
    "\n",
    "if predictions_path.exists():\n",
    "    predictions = pd.read_csv(predictions_path)\n",
    "    predictions_list = predictions[\"image_url\"].tolist()\n",
    "else:\n",
    "    predictions_list = []\n",
    "\n",
    "predictions_list = []\n",
    "output_parser, output_schema, output_example = get_parser()\n",
    "\n",
    "for index, row in df.head(1).iterrows():\n",
    "    image_url = row[\"image_url\"]\n",
    "    retry_count = 0\n",
    "    while retry_count <= retry:\n",
    "        try:\n",
    "            if image_url not in predictions_list:\n",
    "                response, response_parsed = predict_and_save(\n",
    "                    save_data=True,\n",
    "                    output_parser=output_parser,\n",
    "                    image_url=image_url,\n",
    "                    prompt=prompt,\n",
    "                    max_output_token=max_output_token,\n",
    "                    temperature=temperature,\n",
    "                    top_k=top_k,\n",
    "                    top_p=top_p,\n",
    "                    experiment_name=experiment_name,\n",
    "                    experiment_datetime=experiment_datetime,\n",
    "                    predictions_path=predictions_path,\n",
    "                )\n",
    "\n",
    "                print(f\"{index} - {len(df)}\")\n",
    "                # print(json.dumps(response_parsed, indent=4))\n",
    "                # display(get_image_from_url(image_url))\n",
    "            else:\n",
    "                print(f\"{index} - {len(df)}: already predicted\")\n",
    "\n",
    "            retry_count = retry + 1\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"{index} - {len(df)}: Error.. Retrying:{retry_count}\\n {e}\\n\\n\\n\\nAI Response:\")\n",
    "            print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad9663-727a-4620-8525-f2803bde51e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05adb4b9-a7e7-4a2b-927d-0d38a5466434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1145a2-8260-46ec-bb03-b9dcd859ebe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04e2a6-ecdb-4b86-b125-1c35aae3b916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aac9f08-33c6-4a33-8d2c-a7ffadbf2b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(\"gemini-pro-vision\")\n",
    "model.generate_content()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b4c78-5a41-4a3d-8154-2b49f3ad24d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6efc556-4562-4bfa-8ef8-7c894a234990",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad79bb0e-a989-48ec-9e20-7840794439eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_id = \"001477\"\n",
    "N = 100\n",
    "for i, image_url in enumerate(\n",
    "    N * [f\"https://storage.googleapis.com/datario-public/vision-ai/staging/{camera_id}.png\"]\n",
    "):\n",
    "    retry_count = 0\n",
    "    while retry_count <= retry:\n",
    "        try:\n",
    "            response, response_parsed = predict_and_save(\n",
    "                save_data=True,\n",
    "                output_parser=output_parser,\n",
    "                image_url=image_url,\n",
    "                prompt=prompt,\n",
    "                max_output_token=max_output_token,\n",
    "                temperature=temperature,\n",
    "                top_k=top_k,\n",
    "                top_p=top_p,\n",
    "            )\n",
    "\n",
    "            print(f\"{i}\")\n",
    "            # print(json.dumps(response_parsed, indent=4))\n",
    "            # display(get_image_from_url(image_url))\n",
    "            retry_count = retry + 1\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"{i}: Error.. Retrying:{retry_count}\\n {e}\\n\\n\\n\\nAI Response:\")\n",
    "            print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3084e9e8-3a53-49fc-a34c-fab80aa570f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a81b6-0840-4c0c-b3b7-b287a408f738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de45f6-5f96-4bd0-889f-1c77de15e247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2de343-2021-4b9d-bdec-5fad2713b942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c6d823-1be5-41b4-a30a-e8775a8fff20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d617e71e-a3d1-45c3-bf59-3dbad561fad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d42160-cc20-4afe-b88e-cfe5675e3b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6936a0-ded2-4ae8-8817-64fcde85bffc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6ae79b-fb54-404a-a7d6-4c8889282e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7d4d6-e96e-41fe-9385-346a74d9398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db35215f-8f6d-4b8a-98f3-5c7ef1c7ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser.parse(response_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e012c-8c4e-42d6-a915-9c04de0ae0c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f459c94-045e-477d-9e2d-4daae12c3a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557a65b-d976-43d2-ae29-fadba8336f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e416e7-f770-4758-80c1-616e788e4d80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1b1675-9ed5-41a3-96de-ea07b5a17cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ad56f-48c0-493c-8010-2d477f75e015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a93eef-6414-40ca-a260-05b363514053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4d874-13f5-4fc5-9535-2ceb4f35c6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363487d0-abf1-4810-bd4e-af6ecdc9bd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ef2392-2b12-4b5f-adbb-d7ac8808a183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0981861-bf78-4313-9707-78fbeed07676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095f41b9-72f9-4ff4-a92b-90467f0d6985",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa25eb26-86d0-4fbd-baed-32eea8413c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8eb834-0fda-43a1-a48d-38ccfc620cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f249ce22-8953-425f-b048-3799f4132320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f633618-b120-46a9-bebf-571115518247",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a583ac5-28e6-4172-8254-87fcbba4dcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af26c7-c932-44fc-8ff6-06bfd9449586",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63777b1b-9c46-4d4e-81e9-02f8434ce218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320dc68c-282d-42e0-8560-d7efd730678d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8311f0e-d371-431d-87bf-a12cb150c6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f66e1-9636-4e51-9818-a74ac476259a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5aaa57-c42b-4a9d-a641-2fac9f04a490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e727eb-a617-4360-863e-aeb2b16af3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8072c17-f764-4091-98bd-e9a7e04ecb58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948454c4-478a-42b2-8888-c0ee53604edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c131bba-ce3d-4166-b29b-da2209dfa26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65073a69-14c4-429e-8f54-77216854c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "true_values = df_final[\"flood\"].tolist()\n",
    "predicted_values = df_final[\"ai_label\"].tolist()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_values, predicted_values)\n",
    "precision = precision_score(true_values, predicted_values, pos_label=True)\n",
    "recall = recall_score(true_values, predicted_values, pos_label=True)\n",
    "f1 = f1_score(true_values, predicted_values, pos_label=True)\n",
    "conf_matrix = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "# Print metrics\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(true_values, predicted_values)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\"False\", \"True\"],\n",
    "    yticklabels=[\"False\", \"True\"],\n",
    ")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# resize_factor = 3\n",
    "# imgs = 10\n",
    "# time = 1:00\n",
    "# Accuracy: 0.7\n",
    "# Precision: 0.6666666666666666\n",
    "# Recall: 0.5\n",
    "# F1 Score: 0.5714285714285715\n",
    "\n",
    "# resize_factor = 1\n",
    "# imgs = 10\n",
    "# time = 1:15\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75\n",
    "\n",
    "\n",
    "# resize_factor = 5\n",
    "# imgs = 10\n",
    "# time = 1:20\n",
    "# Accuracy: 0.8\n",
    "# Precision: 0.75\n",
    "# Recall: 0.75\n",
    "# F1 Score: 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc24eb2-79a9-4008-a62d-68352822cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[\"miss\"] = np.where(df_final[\"flood\"] == df_final[\"ai_label\"], False, True)\n",
    "mask = df_final[\"miss\"] == True\n",
    "miss = df_final[mask]\n",
    "miss_imgs = miss[\"base64\"].tolist()\n",
    "miss_ai_labels = miss[\"ai_label\"].tolist()\n",
    "\n",
    "\n",
    "for base64_image, ai_label in zip(miss_imgs, miss_ai_labels):\n",
    "    print(f\"AI classyfy as: {ai_label}\")\n",
    "    display_img(base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77779a-d488-4f08-8aea-52394f9741e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ef146-77b9-4969-bce0-c27dc606059b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b32695b-c8a0-46d8-a5e4-2121f88ac158",
   "metadata": {},
   "source": [
    "You are a highly skilled prompt engineering focus in create prompts for CCTV image recognition. Your task is to optimize and refine a provided example prompt.\n",
    "\n",
    "you output is a diff between the provided prompt and the new optmized prompt\n",
    "\n",
    "shall we start?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b74ec-93a9-4328-862f-54c3f1162e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Escritorio de Dados - Default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
